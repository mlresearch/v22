---
title: 'Scaling up Kernel SVM on Limited Resources: A Low-rank Linearization Approach'
abstract: Kernel Support Vector Machine delivers state-of-the-art results in non-linear
  classification, but the need to maintain a large number of support vectors poses
  a challenge in large scale training and testing. In contrast, linear SVM is much
  more scalable even on limited computing recourses (e.g. daily life PCs), but the
  learned model cannot capture non-linear concepts. To scale up kernel SVM on limited
  resources, we propose a low-rank linearization approach that transforms a non-linear
  SVM to a linear one via a novel, approximate empirical kernel map computed from
  efficient low-rank approximation of kernel matrices. We call it LLSVM (Low-rank
  Linearized SVM). We theoretically study the gap between the solutions of the optimal
  and approximate kernel map, which is used in turn to provide important guidance
  on the sampling based kernel approximations. Our algorithm inherits high efficiency
  of linear SVMs and rich repesentability of kernel classifiers. Evaluation against
  large-scale linear and kernel SVMs on several truly large data sets shows that the
  proposed method achieves a better tradeoff between scalability and model representability.
pdf: http://proceedings.mlr.press/v22/zhang12d/zhang12d.pdf
layout: inproceedings
id: zhang12d
month: 0
firstpage: 1425
lastpage: 1434
page: 1425-1434
sections: 
author:
- given: Kai
  family: Zhang
- given: Liang
  family: Lan
- given: Zhuang
  family: Wang
- given: Fabian
  family: Moerchen
date: 2012-03-21
address: La Palma, Canary Islands
publisher: PMLR
container-title: Proceedings of the Fifteenth International Conference on Artificial
  Intelligence and Statistics
volume: '22'
genre: inproceedings
issued:
  date-parts:
  - 2012
  - 3
  - 21
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
