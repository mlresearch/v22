---
title: Lifted coordinate descent for learning with trace-norm regularization
abstract: We consider the minimization of a smooth loss with trace-norm regularization,
  which is a natural objective in multi-class and multi-task learning. Even though
  the problem is convex, existing approaches rely on optimizing a non-convex variational
  bound, which is not guaranteed to converge, or repeatedly perform singular-value
  decomposition, which prevents scaling beyond moderate matrix sizes. We lift the
  non-smooth convex problem into an infinitely dimensional smooth problem and apply
  coordinate descent to solve it. We prove that our approach converges to the optimum,
  and is competitive or outperforms state of the art.
pdf: http://proceedings.mlr.press/v22/dudik12/dudik12.pdf
supplementary: Supplementary:http://jmlr.org/proceedings/papers/v22/dudik12/dudik12Supple.pdf
layout: inproceedings
series: Proceedings of Machine Learning Research
id: dudik12
month: 0
tex_title: Lifted coordinate descent for learning with trace-norm regularization
firstpage: 327
lastpage: 336
page: 327-336
sections: 
author:
- given: Miroslav
  family: Dudik
- given: Zaid
  family: Harchaoui
- given: Jerome
  family: Malick
date: 2012-03-21
address: La Palma, Canary Islands
publisher: PMLR
container-title: Proceedings of the Fifteenth International Conference on Artificial
  Intelligence and Statistics
volume: '22'
genre: inproceedings
issued:
  date-parts:
  - 2012
  - 3
  - 21
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
