---
title: Multi-armed Bandit Problems with History
abstract: In this paper we consider the stochastic multi-armed bandit problem. However,
  unlike in the conventional version of this problem, we do not assume that the algorithm
  starts from scratch. Many applications offer observations of (some of) the arms
  even before the algorithm starts.  We propose three novel multi-armed bandit algorithms
  that can exploit this data. An upper bound on the regret is derived in each case.
  The results show that a logarithmic amount of historic data  can reduce  regret
  from logarithmic to constant. The effectiveness of the proposed algorithms  are
  demonstrated on a large-scale malicious URL detection problem.
pdf: http://proceedings.mlr.press/v22/shivaswamy12/shivaswamy12.pdf
supplementary: Supplementary:http://jmlr.org/proceedings/papers/v22/shivaswamy12/shivaswamy12Supple.pdf
layout: inproceedings
series: Proceedings of Machine Learning Research
id: shivaswamy12
month: 0
firstpage: 1046
lastpage: 1054
page: 1046-1054
sections: 
author:
- given: Pannagadatta
  family: Shivaswamy
- given: Thorsten
  family: Joachims
date: 2012-03-21
address: La Palma, Canary Islands
publisher: PMLR
container-title: Proceedings of the Fifteenth International Conference on Artificial
  Intelligence and Statistics
volume: '22'
genre: inproceedings
issued:
  date-parts:
  - 2012
  - 3
  - 21
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
