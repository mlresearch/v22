---
title: Contextual Bandit Learning with Predictable Rewards
abstract: 'Contextual bandit learning is a reinforcement learning problem where   the
  learner repeatedly receives a set of features (context), takes   an action and receives
  a reward based on the action and context. We   consider this problem under a realizability
  assumption: there exists   a function in a (known) function class, always capable
  of predicting   the expected reward, given the action and context.  Under this   assumption,
  we show three things. We present a new algorithm–Regressor Elimination – with a
  regret similar to the agnostic setting (i.e. in the absence of realizability assumption).
  We prove a new lower bound showing no algorithm can achieve superior performance
  in the worst case even with the realizability assumption. However, we do show that
  for \emphany set of policies (mapping contexts to actions), there is a distribution
  over rewards (given context) such that our new algorithm has \em constant regret
  unlike the previous approaches.'
pdf: http://proceedings.mlr.press/v22/agarwal12/agarwal12.pdf
layout: inproceedings
id: agarwal12
month: 0
firstpage: 19
lastpage: 26
page: 19-26
sections: 
author:
- given: Alekh
  family: Agarwal
- given: Miroslav
  family: Dudik
- given: Satyen
  family: Kale
- given: John
  family: Langford
- given: Robert
  family: Schapire
date: 2012-03-21
address: La Palma, Canary Islands
publisher: PMLR
container-title: Proceedings of the Fifteenth International Conference on Artificial
  Intelligence and Statistics
volume: '22'
genre: inproceedings
issued:
  date-parts:
  - 2012
  - 3
  - 21
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
