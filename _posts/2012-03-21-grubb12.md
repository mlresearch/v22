---
title: 'SpeedBoost: Anytime Prediction with Uniform Near-Optimality'
abstract: We present SpeedBoost, a natural extension of functional gradient descent,
  for learning anytime predictors, which automatically trade computation time for
  predictive accuracy by selecting from a set of simpler candidate predictors. These
  anytime predictors not only generate approximate predictions rapidly, but are capable
  of using extra resources at prediction time, when available, to improve performance.
  We also demonstrate how our framework can be used to select weak predictors which
  target certain subsets of the data, allowing for efficient use of computational
  resources on difficult examples.  We also show that variants of the SpeedBoost algorithm
  produce predictors which are provably competitive with any possible sequence of
  weak predictors with the same total complexity.
pdf: http://proceedings.pmlr.press/grubb12/grubb12.pdf
layout: inproceedings
id: grubb12
month: 0
firstpage: 458
lastpage: 466
page: 458-466
origpdf: http://jmlr.org/proceedings/papers/v22/grubb12/grubb12.pdf
sections: 
author:
- given: Alex
  family: Grubb
- given: Drew
  family: Bagnell
date: 2012-03-21
publisher: PMLR
container-title: Proceedings of the Fifteenth International Conference on Artificial
  Intelligence and Statistics
volume: '22'
genre: inproceedings
issued:
  date-parts:
  - 2012
  - 3
  - 21
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
