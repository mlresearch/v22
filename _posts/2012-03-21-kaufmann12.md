---
title: On Bayesian Upper Confidence Bounds for Bandit Problems
abstract: 'Stochastic bandit problems have been analyzed from two different perspectives:
  a frequentist view, where the parameter is a deterministic unknown quantity, and
  a Bayesian approach, where the parameter is drawn from a prior distribution.  We
  show in this paper that methods derived from this second perspective prove optimal
  when evaluated using the frequentist cumulated regret as a measure of performance.
  We give a general formulation for a class of Bayesian index policies that rely on
  quantiles of the posterior distribution. For binary bandits, we prove that the corresponding
  algorithm, termed Bayes-UCB, satisfies finite-time regret bounds that imply its
  asymptotic optimality.  More generally, Bayes-UCB appears as an unifying framework
  for several variants of the UCB algorithm addressing different bandit problems (parametric
  multi-armed bandits, Gaussian bandits with unknown mean and variance, linear bandits).
  But the generality of the Bayesian approach makes it possible to address more challenging
  models. In particular, we show how to handle linear bandits with sparsity constraints
  by resorting to Gibbs sampling.'
pdf: http://jmlr.org/proceedings/papers/v22/kaufmann12/kaufmann12.pdf
layout: inproceedings
id: kaufmann12
month: 0
firstpage: 592
lastpage: 600
page: 592-600
sections: 
author:
- given: Emilie
  family: Kaufmann
- given: Olivier
  family: Cappe
- given: Aurelien
  family: Garivier
reponame: v22
date: 2012-03-21
address: La Palma, Canary Islands
publisher: PMLR
container-title: Proceedings of the Fifteenth International Conference on Artificial
  Intelligence and Statistics
volume: '22'
genre: inproceedings
issued:
  date-parts:
  - 2012
  - 3
  - 21
# Format based on citeproc: http://blog.martinfenner.org/2013/07/30/citeproc-yaml-for-bibliographies/
---
