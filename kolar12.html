<html><head>
<meta http-equiv="content-type" content="text/html; charset=UTF-8">

<link rel="alternate" type="application/rss+xml" href="http://www.jmlr.org/jmlr.xml" title="JMLR RSS">
<style>. {font-family:verdana,helvetica,sans-serif}
a {text-decoration:none;color:#3030a0}
</style>
<style type="text/css">
<!-- 
#fixed {
    position: absolute;
    top: 0;
    left: 0;
    width: 8em;
    height: 100%;
}
body > #fixed {
    position: fixed;
}
#content {
    margin-top: 1em;
    margin-left: 10em;
    margin-right: 0.5em;
}
img.jmlr {
    width: 7em;
}
img.rss {
    width: 2em;
}
-->
</style>
<script language="JavaScript"> 
<!-- function GoAddress(user,machine) {
document.location = 'mailto:' + user + '@' + machine; } 
// -->
</script>


<style>
. {font-family:verdana,helvetica,sans-serif}
a {text-decoration:none;color:#3030a0}
</style>

<div id="content">
<h2>Marginal Regression For Multitask Learning</h2><p><i><b>Mladen Kolar, Han Liu </b></i>; JMLR W&ampCP 22: 647-655, 2012.</p><h3>Abstract</h3><p>  Variable selection is an important practical problem that arises in
  analysis of many high-dimensional datasets. Convex optimization
  procedures, that arise from relaxing the NP-hard subset selection
  procedure, e.g., the Lasso or Dantzig selector, have become the
  focus of intense theoretical investigations. Although many efficient
  algorithms exist that solve these problems, finding a solution when
  the number of variables is large, e.g., several hundreds of
  thousands in problems arising in genome-wide association analysis,
  is still computationally challenging. A practical solution for these
  high-dimensional problems is the marginal regression, where the
  output is regressed on each variable separately. We investigate
  theoretical properties of the marginal regression in a multitask
  framework. Our contribution include: i) sharp analysis for the
  marginal regression in a single task setting with random design, ii)
  sufficient conditions for the multitask screening to select the
  relevant variables, iii) a lower bound on the Hamming distance
  convergence for multitask variable selection problems. A simulation
  study further demonstrates the performance of the marginal
  regression.</p>
</div>
 <div id="fixed">
<br>
<a align="right" href="http://www.jmlr.org/" target="_top"><img class="jmlr" src="http://jmlr.csail.mit.edu/jmlr.jpg" align="right" border="0"></a>
<p><br><br>
</p><p align="right"> <a href="http://www.jmlr.org/"> Home Page </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/papers"> Papers </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/author-info.html"> Submissions </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/news.html"> News </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/scope.html"> Scope </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/editorial-board.html"> Editorial Board </a> 

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/announcements.html"> Announcements </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/proceedings"> Proceedings </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/mloss">Open Source Software</a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/search-jmlr.html"> Search </a>

</p><p align="right"> <a href="http://jmlr.csail.mit.edu/manudb"> Login </a></p>

<br><br>
<p align="right"> <a href="http://jmlr.csail.mit.edu/jmlr.xml"> 
<img src="http://jmlr.csail.mit.edu/RSS.gif" class="rss" alt="RSS Feed">
</a>



</p></div>
 
<p></p><center>Page last modified on Thu April 26 2012 13:56 2012.</center>

<p> 

<table width="100%"> <tbody><tr>
<td align="right"><font size="-1">Copyright 
@ <a target="_top" href="http://www.jmlr.org/">JMLR</a> 2012.  All rights
reserved.</font></td> </tr> </tbody></table>
</p></body></html>
